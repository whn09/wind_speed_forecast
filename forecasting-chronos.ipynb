{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Chronos\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/timeseries/forecasting-chronos.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/timeseries/forecasting-chronos.ipynb)\n",
    "\n",
    "\n",
    "AutoGluon-TimeSeries (AG-TS) includes [Chronos](https://github.com/amazon-science/chronos-forecasting) family of forecasting models. Chronos models are pretrained on a large collection of real & synthetic time series data, which enables them to make accurate forecasts on new data out of the box.\n",
    "\n",
    "AG-TS provides a robust and easy way to use Chronos through the familiar `TimeSeriesPredictor` API. This tutorial describes how to \n",
    "- Use Chronos models in **zero-shot** mode to make forecasts without any dataset-specific training\n",
    "- **Fine-tune** Chronos models on custom data to improve the accuracy\n",
    "- Handle **covariates & static features** by combining Chronos with a tabular regression model\n",
    "\n",
    ":::{note}\n",
    "\n",
    "**New in v1.2:** AutoGluon now features Chronos-Bolt⚡️ — new, more accurate, and up to 250x faster Chronos models.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# We use uv for faster installation\n",
    "!pip install uv\n",
    "!uv pip install -q autogluon.timeseries --system\n",
    "!uv pip uninstall -q torchaudio torchvision torchtext --system # fix incompatible package versions on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Chronos\n",
    "\n",
    "Being a pretrained model for zero-shot forecasting, Chronos is different from other models available in AG-TS. \n",
    "Specifically, Chronos models do not really `fit` time series data. However, when `predict` is called, they carry out a relatively more expensive computation that scales linearly with the number of time series in the dataset. In this aspect, they behave like local statistical models such as ETS or ARIMA, where all computation happens during inference. \n",
    "\n",
    "AutoGluon supports both the original Chronos models (e.g., [`chronos-t5-large`](https://huggingface.co/autogluon/chronos-t5-large)), as well as the new, more accurate and up to 250x faster Chronos-Bolt⚡ models (e.g., [`chronos-bolt-base`](https://huggingface.co/autogluon/chronos-bolt-base)). \n",
    "\n",
    "The easiest way to get started with Chronos is through the model-specific presets. \n",
    "\n",
    "- **(recommended)** The new, fast Chronos-Bolt️ models can be accessed using the `\"bolt_tiny\"`, `\"bolt_mini\"`, `\"bolt_small\"` and `\"bolt_base\"` presets.\n",
    "- The original Chronos models can be accessed using the `\"chronos_tiny\"`, `\"chronos_mini\"`, `\"chronos_small\"`, `\"chronos_base\"` and `\"chronos_large\"` presets.\n",
    "\n",
    "Note that the original Chronos models of size `small` and above require a GPU to run, while all Chronos-Bolt models can be run both on a CPU and a GPU.\n",
    "\n",
    "Alternatively, Chronos can be combined with other time series models using presets `\"medium_quality\"`, `\"high_quality\"` and `\"best_quality\"`. More details about these presets are available in the documentation for [`TimeSeriesPredictor.fit`](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesPredictor.fit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with a subset of the [Australian Electricity Demand dataset](https://zenodo.org/records/4659727) to see Chronos-Bolt in action.\n",
    "\n",
    "First, we load the dataset as a [TimeSeriesDataFrame](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesDataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T000000</th>\n",
       "      <th>2013-03-10 00:00:00</th>\n",
       "      <td>5207.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 00:30:00</th>\n",
       "      <td>5002.275879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 01:00:00</th>\n",
       "      <td>4747.569824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 01:30:00</th>\n",
       "      <td>4544.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-10 02:00:00</th>\n",
       "      <td>4425.952148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  target\n",
       "item_id timestamp                       \n",
       "T000000 2013-03-10 00:00:00  5207.959961\n",
       "        2013-03-10 00:30:00  5002.275879\n",
       "        2013-03-10 01:00:00  4747.569824\n",
       "        2013-03-10 01:30:00  4544.880859\n",
       "        2013-03-10 02:00:00  4425.952148"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TimeSeriesDataFrame.from_path(\n",
    "    \"https://autogluon.s3.amazonaws.com/datasets/timeseries/australian_electricity_subset/test.csv\"\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the [TimeSeriesPredictor](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesPredictor.html) and select the `\"bolt_small\"` presets to use the Chronos-Bolt (Small, 48M) model in zero-shot mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting the dataframe index before generating the train/test split.\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to '/home/ubuntu/wind_speed_forecast/AutogluonModels/ag-20250415_042015'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #24~22.04.1-Ubuntu SMP Thu Jul 18 10:43:12 UTC 2024\n",
      "CPU Count:          8\n",
      "GPU Count:          1\n",
      "Memory Avail:       36.12 GB / 61.93 GB (58.3%)\n",
      "Disk Space Avail:   863.70 GB / 1938.16 GB (44.6%)\n",
      "===================================================\n",
      "Setting presets to: bolt_small\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': True,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: '30min'\n",
      "Provided train_data has 172800 rows, 5 time series. Median time series length is 34560 (min=34560, max=34560). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-04-15 04:20:17\n",
      "Models that will be trained: ['Chronos[bolt_small]']\n",
      "Training timeseries model Chronos[bolt_small]. \n",
      "2025-04-15 04:20:19.960054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744690819.983516  457171 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744690819.990357  457171 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 04:20:20.017244: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 5.27 s\n",
      "Trainer has no fit models that can predict.\n"
     ]
    }
   ],
   "source": [
    "prediction_length = 48\n",
    "train_data, test_data = data.train_test_split(prediction_length)\n",
    "\n",
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data, presets=\"bolt_small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As promised, Chronos does not take any time to `fit`. The `fit` call merely serves as a proxy for the `TimeSeriesPredictor` to do some of its chores under the hood, such as inferring the frequency of time series and saving the predictor's state to disk. \n",
    "\n",
    "Let's use the `predict` method to generate forecasts, and the `plot` method to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "The node bolt_small is not in the digraph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/classes/digraph.py:954\u001b[0m, in \u001b[0;36mDiGraph.predecessors\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bolt_small'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbolt_small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m predictor\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      3\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m      4\u001b[0m     predictions\u001b[38;5;241m=\u001b[39mpredictions,\n\u001b[1;32m      5\u001b[0m     item_ids\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mitem_ids[:\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      6\u001b[0m     max_history_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m );\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/autogluon/timeseries/predictor.py:856\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m known_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_data_frame(known_covariates)\n\u001b[0;32m--> 856\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mreindex(original_item_id_order, level\u001b[38;5;241m=\u001b[39mITEMID)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/autogluon/timeseries/learner.py:188\u001b[0m, in \u001b[0;36mTimeSeriesLearner.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform_future_known_covariates(known_covariates)\n\u001b[1;32m    187\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_covariates_with_forecast_index(known_covariates\u001b[38;5;241m=\u001b[39mknown_covariates, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:937\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeSeriesDataFrame:\n\u001b[1;32m    936\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_for_prediction(model)\n\u001b[0;32m--> 937\u001b[0m     model_pred_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_pred_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_pred_dict[model_name]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:1211\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.get_model_pred_dict\u001b[0;34m(self, model_names, data, known_covariates, record_pred_time, raise_exception_if_failed, use_cache, random_seed)\u001b[0m\n\u001b[1;32m   1209\u001b[0m model_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[0;32m-> 1211\u001b[0m     model_set\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_minimum_model_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_set) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1213\u001b[0m     model_to_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_levels()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:175\u001b[0m, in \u001b[0;36mSimpleAbstractTrainer.get_minimum_model_set\u001b[0;34m(self, model, include_self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    174\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 175\u001b[0m minimum_model_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfs_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_self:\n\u001b[1;32m    177\u001b[0m     minimum_model_set \u001b[38;5;241m=\u001b[39m [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m minimum_model_set \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m!=\u001b[39m model]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/utils/decorators.py:788\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 4:3\u001b[0m, in \u001b[0;36margmap_bfs_tree_1\u001b[0;34m(G, source, reverse, depth_limit, sort_neighbors, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/utils/backends.py:967\u001b[0m, in \u001b[0;36m_dispatchable.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworkx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m backend is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/algorithms/traversal/breadth_first_search.py:261\u001b[0m, in \u001b[0;36mbfs_tree\u001b[0;34m(G, source, reverse, depth_limit, sort_neighbors)\u001b[0m\n\u001b[1;32m    253\u001b[0m T\u001b[38;5;241m.\u001b[39madd_node(source)\n\u001b[1;32m    254\u001b[0m edges_gen \u001b[38;5;241m=\u001b[39m bfs_edges(\n\u001b[1;32m    255\u001b[0m     G,\n\u001b[1;32m    256\u001b[0m     source,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     sort_neighbors\u001b[38;5;241m=\u001b[39msort_neighbors,\n\u001b[1;32m    260\u001b[0m )\n\u001b[0;32m--> 261\u001b[0m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43medges_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m T\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/classes/digraph.py:792\u001b[0m, in \u001b[0;36mDiGraph.add_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_edges_from\u001b[39m(\u001b[38;5;28mself\u001b[39m, ebunch_to_add, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattr):\n\u001b[1;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add all the edges in ebunch_to_add.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03m    >>> G.add_edges_from(list((5, n) for n in G.nodes))\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mebunch_to_add\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mne\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mne\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/algorithms/traversal/breadth_first_search.py:194\u001b[0m, in \u001b[0;36mbfs_edges\u001b[0;34m(G, source, reverse, depth_limit, sort_neighbors)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m generic_bfs_edges(\n\u001b[1;32m    191\u001b[0m         G, source, \u001b[38;5;28;01mlambda\u001b[39;00m node: \u001b[38;5;28miter\u001b[39m(sort_neighbors(successors(node))), depth_limit\n\u001b[1;32m    192\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m generic_bfs_edges(G, source, successors, depth_limit)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/algorithms/traversal/breadth_first_search.py:93\u001b[0m, in \u001b[0;36mgeneric_bfs_edges\u001b[0;34m(G, source, neighbors, depth_limit)\u001b[0m\n\u001b[1;32m     91\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(G)\n\u001b[1;32m     92\u001b[0m depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 93\u001b[0m next_parents_children \u001b[38;5;241m=\u001b[39m [(source, \u001b[43mneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_parents_children \u001b[38;5;129;01mand\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m depth_limit:\n\u001b[1;32m     95\u001b[0m     this_parents_children \u001b[38;5;241m=\u001b[39m next_parents_children\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.11/site-packages/networkx/classes/digraph.py:956\u001b[0m, in \u001b[0;36mDiGraph.predecessors\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pred[n])\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkXError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in the digraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mNetworkXError\u001b[0m: The node bolt_small is not in the digraph."
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data, model=\"bolt_small\")\n",
    "predictor.plot(\n",
    "    data=data,\n",
    "    predictions=predictions,\n",
    "    item_ids=data.item_ids[:2],\n",
    "    max_history_length=200,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning \n",
    "\n",
    "We have seen above how Chronos models can produce forecasts in zero-shot mode. AutoGluon also makes it easy to fine-tune Chronos models on a specific dataset to maximize the predictive accuracy.\n",
    "\n",
    "The following snippet specifies two settings for the Chronos-Bolt ️(Small) model: zero-shot and fine-tuned. `TimeSeriesPredictor` will perform a lightweight fine-tuning of the pretrained model on the provided training data. We add name suffixes to easily identify the zero-shot and fine-tuned versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 60s\n",
      "AutoGluon will save models to '/local/home/shchuro/workspace/autogluon/docs/tutorials/timeseries/AutogluonModels/ag-20241126_091607'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.2b20241122\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          32\n",
      "GPU Count:          4\n",
      "Memory Avail:       229.82 GB / 239.85 GB (95.8%)\n",
      "Disk Space Avail:   563.58 GB / 1968.52 GB (28.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': False,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': 'ZeroShot'},\n",
      "                                  'model_path': 'bolt_small'},\n",
      "                                 {'ag_args': {'name_suffix': 'FineTuned'},\n",
      "                                  'fine_tune': True,\n",
      "                                  'model_path': 'bolt_small'}]},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 60,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: '30min'\n",
      "Provided train_data has 172800 rows, 5 time series. Median time series length is 34560 (min=34560, max=34560). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-11-26 09:16:07\n",
      "Models that will be trained: ['ChronosZeroShot[bolt_small]', 'ChronosFineTuned[bolt_small]']\n",
      "Training timeseries model ChronosZeroShot[bolt_small]. Training for up to 29.9s of the 59.9s of remaining time.\n",
      "\t-0.0417       = Validation score (-WQL)\n",
      "\t0.10    s     = Training runtime\n",
      "\t0.83    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 59.0s of the 59.0s of remaining time.\n",
      "\tSaving fine-tuned model to /local/home/shchuro/workspace/autogluon/docs/tutorials/timeseries/AutogluonModels/ag-20241126_091607/models/ChronosFineTuned[bolt_small]/W0/fine-tuned-ckpt\n",
      "\t-0.0290       = Validation score (-WQL)\n",
      "\t49.36   s     = Training runtime\n",
      "\t0.07    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['ChronosZeroShot[bolt_small]', 'ChronosFineTuned[bolt_small]']\n",
      "Total runtime: 50.38 s\n",
      "Best model: ChronosFineTuned[bolt_small]\n",
      "Best model score: -0.0290\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": [\n",
    "            {\"model_path\": \"bolt_small\", \"ag_args\": {\"name_suffix\": \"ZeroShot\"}},\n",
    "            {\"model_path\": \"bolt_small\", \"fine_tune\": True, \"ag_args\": {\"name_suffix\": \"FineTuned\"}},\n",
    "        ]\n",
    "    },\n",
    "    time_limit=60,  # time limit in seconds\n",
    "    enable_ensemble=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the default fine-tuning configuration for Chronos by only specifying `\"fine_tune\": True`. However, AutoGluon makes it easy to change other parameters for fine-tuning such as the number of steps or learning rate.\n",
    "```python\n",
    "predictor.fit(\n",
    "    ...,\n",
    "    hyperparameters={\"Chronos\": {\"fine_tune\": True, \"fine_tune_lr\": 1e-4, \"fine_tune_steps\": 2000}},\n",
    ")\n",
    "```\n",
    "\n",
    "For the full list of fine-tuning options, see the Chronos documentation in [Forecasting Model Zoo](forecasting-model-zoo.md#autogluon.timeseries.models.ChronosModel).\n",
    "\n",
    "\n",
    "After fitting, we can evaluate the two model variants on the test data and generate a leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChronosFineTuned[bolt_small]</td>\n",
       "      <td>-0.030785</td>\n",
       "      <td>-0.029021</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>0.073925</td>\n",
       "      <td>49.362413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChronosZeroShot[bolt_small]</td>\n",
       "      <td>-0.041446</td>\n",
       "      <td>-0.041720</td>\n",
       "      <td>0.859698</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.098496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_test  score_val  pred_time_test  \\\n",
       "0  ChronosFineTuned[bolt_small]   -0.030785  -0.029021        0.541208   \n",
       "1   ChronosZeroShot[bolt_small]   -0.041446  -0.041720        0.859698   \n",
       "\n",
       "   pred_time_val  fit_time_marginal  fit_order  \n",
       "0       0.073925          49.362413          2  \n",
       "1       0.825092           0.098496          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning resulted in a more accurate model, as shown by the better `score_test` on the test set.\n",
    "\n",
    "Note that all AutoGluon-TimeSeries models report scores in a \"higher is better\" format, meaning that most forecasting error metrics like WQL are multiplied by -1 when reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating the covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chronos️ is a univariate model, meaning it relies solely on the historical data of the target time series for making predictions. However, in real-world scenarios, additional exogenous information related to the target series (e.g., holidays, promotions) is often available. Leveraging this information when making predictions can improve forecast accuracy. \n",
    "\n",
    "AG-TS now features covariate regressors that can be combined with univariate models like Chronos-Bolt to incorporate exogenous information. \n",
    "A `covariate_regressor` in AG-TS is a tabular regression model that is fit on the known covariates and static features to predict the target column at the each time step. The predictions of the covariate regressor are subtracted from the target column, and the univariate model then forecasts the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scaled_price</th>\n",
       "      <th>promotion_email</th>\n",
       "      <th>promotion_homepage</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1062_101</th>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>0.879130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>0.994517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>1.005513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>0.883309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>661.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     scaled_price  promotion_email  promotion_homepage  \\\n",
       "item_id  timestamp                                                       \n",
       "1062_101 2018-01-01      0.879130              0.0                 0.0   \n",
       "         2018-01-08      0.994517              0.0                 0.0   \n",
       "         2018-01-15      1.005513              0.0                 0.0   \n",
       "         2018-01-22      1.000000              0.0                 0.0   \n",
       "         2018-01-29      0.883309              0.0                 0.0   \n",
       "\n",
       "                     unit_sales  \n",
       "item_id  timestamp               \n",
       "1062_101 2018-01-01       636.0  \n",
       "         2018-01-08       123.0  \n",
       "         2018-01-15       391.0  \n",
       "         2018-01-22       339.0  \n",
       "         2018-01-29       661.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TimeSeriesDataFrame.from_path(\n",
    "    \"https://autogluon.s3.amazonaws.com/datasets/timeseries/grocery_sales/test.csv\",\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a grocery sales dataset to demonstrate how Chronos-Bolt can be combined with a covariate regressor. This dataset includes 3 known covariates: `scaled_price`, `promotion_email` and `promotion_homepage` and the task is to forecast the `unit_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 8\n",
    "train_data, test_data = data.train_test_split(prediction_length=prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fits a TimeSeriesPredictor to forecast `unit_sales` for the next 8 weeks. \n",
    "\n",
    "Note that we have specified the target column we are interested in forecasting and the names of known covariates while constructing the TimeSeriesPredictor. \n",
    "\n",
    "We define two configurations for Chronos-Bolt: \n",
    "- zero-shot configuration that uses only the historical values of `unit_sales` without considering the covariates;\n",
    "- a configuration with a CatBoost regression model as the `covariate_regressor`. Note that we recommend to apply a `target_scaler` when using a covariate regressor. Target scaler ensures that all time series have comparable scales, often leading to better accuracy.\n",
    "\n",
    "Like before, we add suffixes to model names to more easily distinguish them in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 60s\n",
      "AutoGluon will save models to '/local/home/shchuro/workspace/autogluon/docs/tutorials/timeseries/AutogluonModels/ag-20241126_091700'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.2b20241122\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 01:22:11 UTC 2024\n",
      "CPU Count:          32\n",
      "GPU Count:          4\n",
      "Memory Avail:       229.61 GB / 239.85 GB (95.7%)\n",
      "Disk Space Avail:   563.40 GB / 1968.52 GB (28.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': False,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': 'ZeroShot'},\n",
      "                                  'model_path': 'bolt_small'},\n",
      "                                 {'ag_args': {'name_suffix': 'WithRegressor'},\n",
      "                                  'covariate_regressor': 'CAT',\n",
      "                                  'model_path': 'bolt_small',\n",
      "                                  'target_scaler': 'standard'}]},\n",
      " 'known_covariates_names': ['scaled_price',\n",
      "                            'promotion_email',\n",
      "                            'promotion_homepage'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 8,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'unit_sales',\n",
      " 'time_limit': 60,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: 'W-MON'\n",
      "Provided train_data has 7337 rows (NaN fraction=6.6%), 319 time series. Median time series length is 23 (min=23, max=23). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'unit_sales'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['scaled_price', 'promotion_email', 'promotion_homepage']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-11-26 09:17:00\n",
      "Models that will be trained: ['ChronosZeroShot[bolt_small]', 'ChronosWithRegressor[bolt_small]']\n",
      "Training timeseries model ChronosZeroShot[bolt_small]. Training for up to 29.9s of the 59.9s of remaining time.\n",
      "\t-0.4523       = Validation score (-WQL)\n",
      "\t0.02    s     = Training runtime\n",
      "\t0.84    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosWithRegressor[bolt_small]. Training for up to 59.0s of the 59.0s of remaining time.\n",
      "\t-0.3580       = Validation score (-WQL)\n",
      "\t1.00    s     = Training runtime\n",
      "\t0.92    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['ChronosZeroShot[bolt_small]', 'ChronosWithRegressor[bolt_small]']\n",
      "Total runtime: 2.80 s\n",
      "Best model: ChronosWithRegressor[bolt_small]\n",
      "Best model score: -0.3580\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    target=\"unit_sales\",\n",
    "    known_covariates_names=[\"scaled_price\", \"promotion_email\", \"promotion_homepage\"],\n",
    ").fit(\n",
    "    train_data,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": [\n",
    "            # Zero-shot model WITHOUT covariates\n",
    "            {\n",
    "                \"model_path\": \"bolt_small\",\n",
    "                \"ag_args\": {\"name_suffix\": \"ZeroShot\"},\n",
    "            },\n",
    "            # Chronos-Bolt (Small) combined with CatBoost on covariates\n",
    "            {\n",
    "                \"model_path\": \"bolt_small\",\n",
    "                \"covariate_regressor\": \"CAT\",\n",
    "                \"target_scaler\": \"standard\",\n",
    "                \"ag_args\": {\"name_suffix\": \"WithRegressor\"},\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    enable_ensemble=False,\n",
    "    time_limit=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the predictor has been fit, we can evaluate it on the test dataset and generate the leaderboard. We see that the model that utilizes the covariates produces a more accurate forecast on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChronosWithRegressor[bolt_small]</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-0.358048</td>\n",
       "      <td>0.881176</td>\n",
       "      <td>0.916053</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChronosZeroShot[bolt_small]</td>\n",
       "      <td>-0.318562</td>\n",
       "      <td>-0.452296</td>\n",
       "      <td>0.859930</td>\n",
       "      <td>0.844927</td>\n",
       "      <td>0.019435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  score_test  score_val  pred_time_test  \\\n",
       "0  ChronosWithRegressor[bolt_small]   -0.268969  -0.358048        0.881176   \n",
       "1       ChronosZeroShot[bolt_small]   -0.318562  -0.452296        0.859930   \n",
       "\n",
       "   pred_time_val  fit_time_marginal  fit_order  \n",
       "0       0.916053           1.004376          2  \n",
       "1       0.844927           0.019435          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the covariates may not always be useful — for some datasets, the zero-shot model may achieve better accuracy. Therefore, it's always important to try out multiple models and select the one that achieves the best accuracy on held-out data. This is done automatically in AutoGluon's `\"high_quality\"` and `\"best_quality\"` presets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "\n",
    "#### How accurate is Chronos?\n",
    "\n",
    "In several independent evaluations we found Chronos to be effective in zero-shot forecasting. \n",
    "The accuracy of Chronos-Bolt (base) often exceeds statistical baseline models, and is often comparable to deep learning \n",
    "models such as `TemporalFusionTransformer` or `PatchTST`.\n",
    "\n",
    "#### What is the recommended hardware for running Chronos models?\n",
    "\n",
    "For fine-tuning and inference with larger Chronos and Chronos-Bolt models, we tested the AWS `g5.2xlarge` and `p3.2xlarge` instances that feature NVIDIA A10G and V100 GPUs, with at least 16GiB of GPU memory and 32GiB of main memory. \n",
    "\n",
    "Chronos-Bolt models can also be used on CPU machines, but this will typically result in a longer runtime.\n",
    "\n",
    "\n",
    "#### Where can I ask specific questions on Chronos?\n",
    "\n",
    "The AutoGluon team are among the core developers of Chronos. So you can ask Chronos-related questions on AutoGluon channels such \n",
    "as the Discord [server](https://discord.gg/wjUmjqAc2N), or [GitHub](https://github.com/autogluon/autogluon). You can also join \n",
    "the discussion on the Chronos GitHub [page](https://github.com/amazon-science/chronos-forecasting/discussions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
